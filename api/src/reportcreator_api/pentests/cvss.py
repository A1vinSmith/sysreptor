import imp
import math
import re
from typing import Any, Union

from django.core.exceptions import ValidationError
from django.utils.translation import gettext_lazy as _
from django.db import models


class CVSSLevel(models.TextChoices):
    NONE = 'none', _('None')
    LOW = 'low', _('Low')
    MEDIUM = 'medium', _('Medium')
    HIGH = 'high', _('High')
    CRITICAL = 'critical', _('Critical')


CVSS3_REGEX = re.compile(r'^CVSS:3.[01](/[A-Za-z]+:[A-Za-z])+$')
CVSS3_METRICS = {
    'AV': {'N': 0.85, 'A': 0.62, 'L': 0.55, 'P': 0.2},
    'AC': {'L': 0.77, 'H': 0.44},
    'PR': {'N': {'U': 0.85, 'C': 0.85}, 'L': {'U': 0.62, 'C': 0.68}, 'H': {'U': 0.27, 'C': 0.5}},
    'UI': {'N': 0.85, 'R': 0.62},
    'S': {'U': 'U', 'C': 'C'},
    'C': {'N': 0, 'L': 0.22, 'H': 0.56},
    'I': {'N': 0, 'L': 0.22, 'H': 0.56},
    'A': {'N': 0, 'L': 0.22, 'H': 0.56},

    'E': {'X': 1, 'H': 1, 'F': 0.97, 'P': 0.94, 'U': 0.91},
    'RL': {'X': 1, 'U': 1, 'W': 0.97, 'T': 0.96, 'O': 0.95},
    'RC': {'X': 1, 'C': 1, 'R': 0.96, 'U': 0.92},

    'CR': {'X': 1, 'L': 0.5, 'M': 1, 'H': 1.5},
    'IR': {'X': 1, 'L': 0.5, 'M': 1, 'H': 1.5},
    'AR': {'X': 1, 'L': 0.5, 'M': 1, 'H': 1.5},
    'MAV': {'X': None, 'N': 0.85, 'A': 0.62, 'L': 0.55, 'P': 0.2},
    'MAC': {'X': None, 'L': 0.77, 'H': 0.44},
    'MPR': {'X': None, 'N': {'U': 0.85, 'C': 0.85}, 'L': {'U': 0.62, 'C': 0.68}, 'H': {'U': 0.27, 'C': 0.5}},
    'MUI': {'X': None, 'N': 0.85, 'R': 0.62},
    'MS': {'X': None, 'U': 'U', 'C': 'C'},
    'MC': {'X': None, 'N': 0, 'L': 0.22, 'H': 0.56},
    'MI': {'X': None, 'N': 0, 'L': 0.22, 'H': 0.56},
    'MA': {'X': None, 'N': 0, 'L': 0.22, 'H': 0.56},
}
CVSS3_REQUIRED_METRICS = ['AV', 'AC', 'PR', 'UI', 'S', 'C', 'I', 'A']

CVSS2_REGEX = re.compile(r'(/?[A-Za-z]+:[A-Z]+)+')
CVSS2_METRICS = {
    'AV': {'L': 0.395, 'A': 0.646, 'N': 1.0},
    'AC': {'H': 0.35, 'M': 0.61, 'L': 0.71},
    'Au': {'M': 0.45, 'S': 0.56, 'N': 0.71},
    'C': {'N': 0, 'P': 0.275, 'C': 0.660},
    'I': {'N': 0, 'P': 0.275, 'C': 0.660},
    'A': {'N': 0, 'P': 0.275, 'C': 0.660},

    'E': {'ND': 1, 'H': 1, 'F': 0.95, 'P': 0.90, 'U': 0.85},
    'RL': {'ND': 1, 'U': 1, 'W': 0.95, 'TF': 0.90, 'OF': 0.87},
    'RC': {'ND': 1, 'C': 1, 'UR': 0.95, 'UC': 0.90},

    'CDP': {'ND': 0, 'N': 0, 'L': 0.1, 'LM': 0.3, 'MH': 0.4, 'H': 0.5},
    'TD': {'ND': 1, 'N': 0, 'L': 0.25, 'M': 0.75, 'H': 1},
    'CR': {'ND': 1, 'L': 0.5, 'M': 1, 'H': 1.51},
    'IR': {'ND': 1, 'L': 0.5, 'M': 1, 'H': 1.51},
    'AR': {'ND': 1, 'L': 0.5, 'M': 1, 'H': 1.51},
}
CVSS2_REQUIRED_METRICS = ['AV', 'AC', 'Au', 'C', 'I', 'A']


def parse_cvss3(vector):
    """
    Parses CVSS3.0 and CVSS3.1 vectors.
    For CVSS 3.0 and 3.1 the metrics and formulas are the same. Only descriptions and definitions changed.
    """
    if not vector or not CVSS3_REGEX.match(vector):
        raise ValidationError('Invalid CVSS3 vector: Invalid format')

    # parse CVSS metrics
    values = dict(map(lambda p: tuple(p.split(':')), filter(None, vector[8:].split('/'))))
    for k, v in values.items():
        if k not in CVSS3_METRICS or v not in CVSS3_METRICS[k]:
            raise ValidationError(f'Invalid CVSS3 vector: invalid metric value "{k}:{v}"')

    # Validate required metrics
    for m in CVSS3_REQUIRED_METRICS:
        if m not in values:
            raise ValidationError(f'Invalid CVSS3 vector: base metric "{m}" missing')

    return values


def is_cvss3(vector):
    try:
        parse_cvss3(vector)
        return True
    except ValidationError:
        return False


def calculate_score_cvss3(vector) -> Union[float, None]:
    try:
        values = parse_cvss3(vector)
    except ValidationError:
        return None

    def metric(name) -> Any:
        # First try modified metric, then original metric, then X (Not Definied)
        m = CVSS3_METRICS.get('M' + name, {}).get(values.get('M' + name))
        if m is not None:
            return m
        m = CVSS3_METRICS.get(name, {}).get(values.get(name))
        if m is not None:
            return m
        return CVSS3_METRICS.get(name, {}).get('X')

    def round_up(inp):
        return math.ceil(inp * 10) / 10

    # Environmental Score calculation (this is the final score shown to the user)
    scope_changed = metric('S') == 'C'
    impact = min(1 - (
            (1 - metric('C') * metric('CR')) *
            (1 - metric('I') * metric('IR')) *
            (1 - metric('A') * metric('AR'))
    ), 0.915)
    impact = 7.52 * (impact - 0.029) - 3.25 * pow(impact - 0.2, 15) if scope_changed else 6.42 * impact
    exploitability = 8.22 * metric('AV') * metric('AC') * metric('PR')[metric('S')] * metric('UI')
    score = 0.0 if impact <= 0 else (
        round_up(min(1.08 * (impact + exploitability), 10)) if scope_changed else
        round_up(min(impact + exploitability, 10))
    )
    score = round_up(score * metric('E') * metric('RL') * metric('RC'))
    return score


def parse_cvss2(vector):
    # Strip non-standardized prefix
    vector = (vector or '').replace('CVSS2#', '')

    if not vector or not CVSS2_REGEX.match(vector):
        raise ValidationError('Invalid CVSS2 vector: Invalid format')

    # parse CVSS metrics
    values = dict(map(lambda p: tuple(p.split(':')), filter(None, vector.split('/'))))
    for k, v in values.items():
        if k not in CVSS2_METRICS or v not in CVSS2_METRICS[k]:
            raise ValidationError(f'Invalid CVSS2 vector: invalid metric value "{k}:{v}"')

    # Validate required metrics
    for m in CVSS2_REQUIRED_METRICS:
        if m not in values:
            raise ValidationError(f'Invalid CVSS2 vector: base metric "{m}" missing')

    return values


def is_cvss2(vector):
    try:
        parse_cvss2(vector)
        return True
    except ValidationError:
        return False


def calculate_score_cvss2(vector):
    try:
        values = parse_cvss2(vector)
    except ValidationError as ex:
        return None

    def metric(name):
        m = CVSS2_METRICS.get(name, {}).get(values.get(name))
        if m is not None:
            return m
        return CVSS2_METRICS.get(name, {}).get('ND')

    def round_up(inp):
        return round(inp, ndigits=1)

    # Environmental Score calculation (this is the final score shown to the user)
    adjusted_impact = min(10.41 * (1 - (
        (1 - metric('C') * metric('CR')) *
        (1 - metric('I') * metric('IR')) *
        (1 - metric('A') * metric('AR')))
    ), 10)
    exploitability = 20 * metric('AV') * metric('AC') * metric('Au')
    adjusted_base_score = round_up(
        ((0.6 * adjusted_impact) + (0.4 * exploitability) - 1.5) *
        (0 if adjusted_impact == 0 else 1.176))
    adjusted_temporal = round_up(adjusted_base_score * metric('E') * metric('RL') * metric('RC'))
    environmental_score = round_up((adjusted_temporal + (10 - adjusted_temporal) * metric('CDP')) * metric('TD'))
    return environmental_score


def is_cvss(vector):
    return is_cvss3(vector) or is_cvss2(vector)


def calculate_score(vector) -> float:
    """
    Calculate the CVSS score from a CVSS vector.
    Supports CVSS v2, v3.0 and v3.1
    """
    if (score := calculate_score_cvss3(vector)) is not None:
        return score
    elif (score := calculate_score_cvss2(vector)) is not None:
        return score
    return 0.0


def level_from_score(score: float) -> CVSSLevel:
    """
    Calculate the CVSS level from a CVSS score.
    """
    if score >= 9.0:
        return CVSSLevel.CRITICAL
    elif score >= 7.0:
        return CVSSLevel.HIGH
    elif score >= 4.0:
        return CVSSLevel.MEDIUM
    elif score > 0:
        return CVSSLevel.LOW
    else:
        return CVSSLevel.NONE


def level_number_from_score(score: float) -> int:
    if score >= 9.0:
        return 5
    elif score >= 7.0:
        return 4
    elif score >= 4.0:
        return 3
    elif score > 0:
        return 2
    else:
        return 1
